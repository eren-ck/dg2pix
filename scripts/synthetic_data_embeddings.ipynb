{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create the synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs to embedd - 2000 at the end \n",
    "graphs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add complete graphs between 0-200\n",
    "for i in range(0,200):\n",
    "    n = (i%50)+1\n",
    "    graphs.append(nx.complete_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add barbell_graph with 200-400\n",
    "for i in range(0,100):\n",
    "    n = (i%40)+2\n",
    "    m = (i%20)+2\n",
    "    graphs.append(nx.barbell_graph(n,m))\n",
    "for i in range(0,100):\n",
    "    n = (i%10)+2\n",
    "    m = (i%30)+2\n",
    "    graphs.append(nx.barbell_graph(n,m))\n",
    "    \n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add balenced trees height between 400 - 450\n",
    "for i in range(0,20):\n",
    "    n = (i%5)+1\n",
    "    graphs.append(nx.balanced_tree(2,n))\n",
    "    graphs.append(nx.balanced_tree(3,n))\n",
    "for i in range(1,6):\n",
    "    graphs.append(nx.balanced_tree(4,i))\n",
    "    graphs.append(nx.balanced_tree(5,i))\n",
    "\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add star graphs with 450-500\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.star_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cycle_graph with 500-550\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.cycle_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path_graph with 550-600\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.path_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add grid_2d_graph with 600-650\n",
    "for i in range(1,26):\n",
    "    n = (i%10)+1\n",
    "    m = (i%20)+1\n",
    "    graphs.append(nx.grid_2d_graph(n,m))\n",
    "    graphs.append(nx.grid_2d_graph(m,n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add caveman_graph with 650-700\n",
    "for i in range(1,51):\n",
    "    n = (i%20)+1\n",
    "    m = (i%5)+1\n",
    "    graphs.append(nx.caveman_graph(n,m))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wheel_graph with 700-750\n",
    "for i in range(1,51):\n",
    "    n = (i%25)+1\n",
    "    graphs.append(nx.wheel_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add star graphs with 750-800\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.star_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add complete_graph with 800-900\n",
    "for i in range(0,100):\n",
    "    n = (i%30)+1\n",
    "    graphs.append(nx.complete_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add caveman_graph with 900-950\n",
    "for i in range(1,51):\n",
    "    n = (i%10)+1\n",
    "    m = (i%7)+1\n",
    "    graphs.append(nx.caveman_graph(n,m))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path_graph with 950-1000\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.path_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add barbell_graph with 1000-1200\n",
    "for i in range(0,100):\n",
    "    n = (i%10)+2\n",
    "    m = (i%15)+2\n",
    "    graphs.append(nx.barbell_graph(n,m))\n",
    "for i in range(0,100):\n",
    "    n = (i%20)+2\n",
    "    m = (i%25)+2\n",
    "    graphs.append(nx.barbell_graph(n,m))\n",
    "    \n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cycle_graph with 1200-1250\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.cycle_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add star graphs with 1250-1300\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.star_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add complete graphs between 1300-1400\n",
    "for i in range(0,100):\n",
    "    n = (i%30)+1\n",
    "    graphs.append(nx.complete_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wheel_graph with 1400-1450\n",
    "for i in range(1,51):\n",
    "    n = (i%20)+1\n",
    "    graphs.append(nx.wheel_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cycle_graph with 1450-1500\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.cycle_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add complete graphs between 1500-1600\n",
    "for i in range(0,100):\n",
    "    n = (i%20)+20\n",
    "    graphs.append(nx.complete_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add grid_2d_graph with 1600-1650\n",
    "for i in range(1,26):\n",
    "    n = (i%10)+1\n",
    "    m = (i%8)+1\n",
    "    graphs.append(nx.grid_2d_graph(n,m))\n",
    "    graphs.append(nx.grid_2d_graph(m,n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path_graph with 1650-1700\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.path_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add balenced trees height between 1700 - 1750\n",
    "for i in range(0,20):\n",
    "    n = (i%6)+1\n",
    "    graphs.append(nx.balanced_tree(2,n))\n",
    "    graphs.append(nx.balanced_tree(3,n))\n",
    "for i in range(2,7):\n",
    "    graphs.append(nx.balanced_tree(4,i))\n",
    "    graphs.append(nx.balanced_tree(5,i))\n",
    "\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cycle_graph with 1750-1800\n",
    "for i in range(1,51):\n",
    "    graphs.append(nx.cycle_graph(i))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add barbell_graph with 1800-1900\n",
    "for i in range(0,100):\n",
    "    n = (i%15)+2\n",
    "    m = (i%25)+2\n",
    "    graphs.append(nx.barbell_graph(n,m))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add complete graphs between 1900-1950\n",
    "for i in range(0,50):\n",
    "    n = (i%10)+25\n",
    "    graphs.append(nx.complete_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wheel_graph with 1950-2000\n",
    "for i in range(1,51):\n",
    "    n = (i%10)+20\n",
    "    graphs.append(nx.wheel_graph(n))\n",
    "print(len(graphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Compute the graph layout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = nx.compose_all(graphs)\n",
    "G = nx.Graph()\n",
    "for graph in tqdm(graphs):\n",
    "    G.add_nodes_from(graph.nodes(data=True))\n",
    "    G.add_edges_from(graph.edges(data=True))\n",
    "\n",
    "coordinates = nx.spring_layout(G, iterations=100)\n",
    "\n",
    "# -- Alternative graph layouts for example --\n",
    "# coordinates = nx.kamada_kawai_layout(G)\n",
    "# coordinates = nx.spectral_layout(G)\n",
    "# coordinates = nx.circular_layout(G)\n",
    "# coordinates = nx.random_layout(G)\n",
    "\n",
    "print('Layout done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinates to list     \n",
    "coordinates = {k: v.tolist() for k, v in coordinates.items()}\n",
    "# modify positions \n",
    "for graph in tqdm(graphs):\n",
    "    nx.set_node_attributes(graph, coordinates, 'coord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time attribute to synthetic data \n",
    "for index, G in enumerate(graphs):\n",
    "    date = datetime.date.today() + datetime.timedelta(days=math.floor(index/24))\n",
    "    hour = index%24\n",
    "    G.graph['time'] = (date, hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'synthetic_data.pkl'\n",
    "pickle.dump( graphs, open( filename, 'wb' ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Compute the graph embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from karateclub import Graph2Vec, GL2Vec, FGSD\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = 'synthetic_data.pkl'\n",
    "with open(data_filename, 'rb') as f:\n",
    "    graphs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Snapshot:\n",
    "    def __init__(self, graphs, indx1, indx2):\n",
    "        \"\"\"Initialize snapshot from a list of graphs.\n",
    "\n",
    "            Keyword arguments:\n",
    "            graphs -- list of networkX graphs \n",
    "            indx1 -- first index in the overall graph list\n",
    "            indx2 -- last index in the overall graph list \n",
    "        \"\"\"\n",
    "        self.graphs = graphs[indx1:indx2]\n",
    "        self.indx1 = indx1\n",
    "        self.indx2 = indx2\n",
    "        self.time1 = datetime.datetime.combine(self.graphs[0].graph['time'][0], datetime.time(self.graphs[0].graph['time'][1])) # .item()\n",
    "        self.time2 = datetime.datetime.combine(self.graphs[-1].graph['time'][0], datetime.time(self.graphs[-1].graph['time'][1])) # .item()\n",
    "        self.duration = self.time2 - self.time1\n",
    "        self.union_g = None\n",
    "        \n",
    "        # occurences of nodes over time in a dict \n",
    "        nodes = []\n",
    "        for g in self.graphs:\n",
    "            nodes.append(g.nodes)\n",
    "        # get number of occurences \n",
    "        self.node_occ = Counter(x for xs in nodes for x in set(xs))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return 'Snapshot: ' + str(self.time1) + ' - ' + str(self.time2) \n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Snapshot: ' + str(self.time1) + ' - ' + str(self.time2) \n",
    "    \n",
    "    def union_graph(self):\n",
    "        if not self.union_g:\n",
    "            G = nx.Graph()\n",
    "            for graph in self.graphs:\n",
    "                G.add_nodes_from(graph.nodes(data=True))\n",
    "                G.add_edges_from(graph.edges(data=True))\n",
    "            self.union_g = G\n",
    "        return self.union_g\n",
    "        \n",
    "    def get_summaries(self, num):\n",
    "        \"\"\"Return all graph supergraphs in a list.\n",
    "        \"\"\"\n",
    "        return [self.union_graph()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Level:\n",
    "    def __init__(self, graphs, level):\n",
    "        \"\"\"Initialize a level from from a list of graphs.\n",
    "\n",
    "            Keyword arguments:\n",
    "            graphs -- list of networkX graphs \n",
    "            level -- number for the level used to create window size \n",
    "        \"\"\"\n",
    "        self.graphs = graphs\n",
    "        self.level = level \n",
    "        self.window_size = int(math.pow(2, (level-1)))\n",
    "        \n",
    "        # initialize the snapshots  \n",
    "        if self.window_size < 1: \n",
    "            raise ValueError('Window size of level below 1')\n",
    "        if self.window_size >= 1:\n",
    "            self.snapshots = []\n",
    "            for i in range(0, len(self.graphs), self.window_size):\n",
    "                self.snapshots.append(Snapshot(self.graphs, i, i+self.window_size))\n",
    "        else: \n",
    "            self.snapshots = self.graphs \n",
    "        \n",
    "    def __repr__(self):\n",
    "        return 'Window size: ' + str(self.window_size) \n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Window size: ' + str(self.window_size)\n",
    "    \n",
    "    def get_graphs(self):\n",
    "        \"\"\"Return all graphs of the level. Returns a dict with key:[union_grap].\n",
    "        The key is the index in the snapshots array.\n",
    "        \"\"\"\n",
    "        print('Level: ' + str(self.level))\n",
    "        result = {}\n",
    "        for index, snap in tqdm(enumerate(self.snapshots)):\n",
    "            result[index] = snap.get_summaries(self.window_size)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hierarchy:\n",
    "    def __init__(self, graphs):\n",
    "        \"\"\"Initialize the hierarchy from a list of graphs.\n",
    "\n",
    "            Keyword arguments:\n",
    "            graphs -- list of networkX graphs \n",
    "        \"\"\"\n",
    "        self.graphs = graphs\n",
    "        self.levels = {}\n",
    "        self.height = 1\n",
    "        \n",
    "        window = 1\n",
    "        while window < len(self.graphs):\n",
    "            window = int(math.pow(2, (self.height-1)))\n",
    "            self.levels[self.height] = Level(self.graphs, self.height)\n",
    "            self.height = self.height + 1\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.levels)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.levels\n",
    "    \n",
    "    def get_graphs(self):\n",
    "        \"\"\"Return all graphs of the hierarchy. Returns a dict of all graphs and a tuple of keys - refering to the elements.\n",
    "        \"\"\"\n",
    "        result = {}\n",
    "        for key, value in self.levels.items():\n",
    "            result[key] = value.get_graphs()\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = Hierarchy(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_graphs = h.get_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_dict(dd, separator='_', prefix=''):\n",
    "    return { str(prefix) + str(separator) + str(k) if prefix else k : v\n",
    "             for kk, vv in dd.items()\n",
    "             for k, v in flatten_dict(vv, separator, kk).items()\n",
    "             } if isinstance(dd, dict) else { prefix : dd }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the dict and get the graphs and keys \n",
    "all_graphs = flatten_dict(all_graphs)\n",
    "graph_to_embed = [item for sublist in list(all_graphs.values()) for item in sublist]\n",
    "graph_keys = list(all_graphs.keys())\n",
    "graph_keys = list(itertools.chain.from_iterable(itertools.repeat(x, 1) for x in graph_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Graph2Vec(workers=4, epochs=epochs)\n",
    "model.fit(graph_to_embed)\n",
    "grap2vec_embeddings = model.get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(grap2vec_embeddings))\n",
    "print(len(grap2vec_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GL2Vec(workers=4, epochs=epochs)\n",
    "model.fit(graph_to_embed)\n",
    "gl2vec_embeddings = model.get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gl2vec_embeddings))\n",
    "print(len(gl2vec_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FGSD(hist_bins=128, hist_range=10)\n",
    "model.fit(graph_to_embed)\n",
    "fgsd_embeddings = model.get_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fgsd_embeddings))\n",
    "print(len(fgsd_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'graph2vec' : grap2vec_embeddings,\n",
    "          'gl2vec' : gl2vec_embeddings,\n",
    "          'fgsd' : fgsd_embeddings,\n",
    "          'keys' : graph_keys\n",
    "         }\n",
    "# keys are build with \"level_internal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'synthetic_data_embeddings.pkl'\n",
    "pickle.dump(result, open( filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two exported files `synthetic_data.pkl` and the `synthetic_data_embeddings.pkl` are then used as inputs to the Flask application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
